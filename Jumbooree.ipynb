{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwdE6+yP7bUPuhdRqkQQcN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hardikdhamija96/Jamboree_CaseStudy/blob/main/Jumbooree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”·Problem Statement â€” Jamboree Graduate Admissions\n",
        "================================================================\n",
        "\n",
        "Business context\n",
        "----------------\n",
        "\n",
        "Jamboree has launched an online â€œChance of Admitâ€ checker for study-abroad aspirants. The tool should be credible, transparent, and useful for counselling teams and marketing funnels. We need a data-driven model that explains what drives admits and gives an accurate probability estimate for each student profile.\n",
        "\n",
        "Objective\n",
        "---------\n",
        "\n",
        "*   **Primary**: Build an interpretable regression model to estimate **Chance of Admit** for an applicant, given profile attributes.\n",
        "    \n",
        "*   **Secondary**: Identify the **key drivers** that most influence admit probability and quantify their impact so counselling can guide students on practical improvements.\n",
        "    \n",
        "\n",
        "Decisions this will enable\n",
        "--------------------------\n",
        "\n",
        "*   **Student guidance**: What to improve first (GRE, TOEFL, SOP, LOR, GPA, research) to meaningfully lift admit chance.\n",
        "    \n",
        "*   **Lead qualification**: Prioritise high potential leads for counsellor follow-ups.\n",
        "    \n",
        "*   **Content and prep strategy**: Which score bands and profile gaps to target in blogs, ads, and workshops.\n",
        "    \n",
        "*   **Scholarship or premium service targeting**: Identify segments with strong lift potential.\n",
        "    \n",
        "\n",
        "Target variable and inputs\n",
        "--------------------------\n",
        "\n",
        "*   **Target**: Chance of Admit (0 to 1).\n",
        "    \n",
        "*   **Predictors**: GRE Score, TOEFL Score, University Rating, SOP Strength, LOR Strength, Undergrad GPA, Research Experience (0 or 1).\n",
        "    \n",
        "*   **Identifier to drop**: Serial No.\n",
        "    \n",
        "\n",
        "Modelling scope and approach\n",
        "----------------------------\n",
        "\n",
        "*   **Scope**: Supervised regression with **explanatory focus**.\n",
        "    \n",
        "*   **Baseline**: OLS Linear Regression using statsmodels to get coefficients, p-values, confidence intervals, and model diagnostics.\n",
        "    \n",
        "*   **Regularised variants**: Ridge and Lasso to handle multicollinearity and improve generalisation; compare with OLS.\n",
        "    \n",
        "*   **Assumption checks**: VIF for multicollinearity, residual mean near zero, linearity via residual plots, homoscedasticity, and normality of residuals.\n",
        "    \n",
        "\n",
        "Success criteria\n",
        "----------------\n",
        "\n",
        "*   **Quality**: Reasonable Train vs Test parity on **MAE, RMSE, RÂ², Adjusted RÂ²** with no obvious overfit.\n",
        "    \n",
        "*   **Interpretability**: Clear ranking of drivers and practical interpretation of coefficients.\n",
        "    \n",
        "*   **Calibration**: Predicted probabilities align with observed bands on hold-out data.\n",
        "    \n",
        "*   **Actionability**: Concrete recommendations that a student can act on to lift chances.\n",
        "    \n",
        "\n",
        "Constraints and considerations\n",
        "------------------------------\n",
        "\n",
        "*   Data represents past applicants; there may be **selection bias** and noisy proxies like University Rating.\n",
        "    \n",
        "*   Relationships may be **nonlinear**; we begin with linear and expand only if diagnostics demand.\n",
        "    \n",
        "*   Keep the tool **simple and transparent** for counselling conversations."
      ],
      "metadata": {
        "id": "MqdEXGkhdz92"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CSTxAQQZQEc",
        "outputId": "e1fbc56e-722a-4fc8-d837-80278a23ce19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "file_id = \"1Ym9Zt60vgOReap1cGFM1L7-actKbynyk\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"jumboree.csv\", quiet=False)"
      ],
      "metadata": {
        "id": "vwullj91ZSv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"jumboree.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ZSRnGIxdZwa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Ume5xXVlZ10g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "i8AcTJ8X1H8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "cRTJkh3L1Kwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "k5VfZqiV1TWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Dataset has 500 complete entries, no missing values, with GRE/TOEFL/CGPA showing strong academic profiles (averages: GRE ~316, TOEFL ~107, CGPA ~8.6).\n",
        "    \n",
        "*   SOP/LOR average ~3.3â€“3.5, Research done by ~56% applicants; Chance of Admit mean ~0.72 (range 0.34â€“0.97).\n",
        "    \n",
        "*   Data is clean, realistic, and well-suited for regression after dropping the Serial No.."
      ],
      "metadata": {
        "id": "e6AndKXsejSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=[\"Serial No.\"], inplace=True)"
      ],
      "metadata": {
        "id": "bbEHi4X11X8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "U0Did2WG2Ah4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "2C6VEnGu2Bw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "bRK8b6nn2JHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "rtszSPhN2hkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Unique ID dropped**: Serial No. removed as it has no predictive value.\n",
        "    \n",
        "*   **Duplicates & nulls**: None found (0 duplicates, 0 nulls) â†’ dataset is clean and consistent.\n",
        "    \n",
        "*   âœ… Data is now model-ready for EDA and preprocessing, with 8 meaningful variables remaining."
      ],
      "metadata": {
        "id": "w5A466emfPcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "continous_features = ['GRE Score', 'TOEFL Score','CGPA','Chance of Admit']"
      ],
      "metadata": {
        "id": "7a52ulVS2vOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'Chance of Admit ':'Chance of Admit'}, inplace=True)"
      ],
      "metadata": {
        "id": "7xEzUvZ93Ly1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "id": "Rjo4LBq-3NRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[continous_features].describe()"
      ],
      "metadata": {
        "id": "sLgRnXnK3oDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "X4r_nZrr4rE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,axes = plt.subplots(1,4, figsize=(14,4))\n",
        "\n",
        "for ax,col in zip(axes,continous_features):\n",
        "  ax.hist(df[col])\n",
        "  ax.set_title(col)\n",
        "  ax.set_xlabel(\"Value\")\n",
        "  ax.set_ylabel(\"Frequency\")\n",
        "  ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oBTtqU0b44dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **GRE & TOEFL**: Both show near-normal distributions with concentration in the upper ranges, confirming applicants are generally high scorers.\n",
        "    \n",
        "*   **CGPA**: Clustered around 8â€“9, with only a few low values â†’ reflects a competitive pool.\n",
        "    \n",
        "*   **Chance of Admit**: Most students fall in 0.6â€“0.9 range, with a clear skew towards higher admit probabilities."
      ],
      "metadata": {
        "id": "TeqB7_VVgJvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,axes = plt.subplots(1,4, figsize=(14,4))\n",
        "\n",
        "for ax,col in zip(axes,continous_features):\n",
        "  ax.boxplot(df[col])\n",
        "  ax.set_title(col)\n",
        "  ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T77jDXbi47Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **GRE & TOEFL**: Scores are tightly distributed with no major outliers, most students performing in higher bands.\n",
        "    \n",
        "*   **CGPA**: Concentrated between 8â€“9; spread is limited and no extreme anomalies.\n",
        "    \n",
        "*   **Chance of Admit**: Mostly between 0.6â€“0.9, with a few lower-end outliers (<0.4) indicating weaker profiles."
      ],
      "metadata": {
        "id": "3fFsTTyMgVDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,axes = plt.subplots(1,4, figsize=(14,4))\n",
        "\n",
        "for ax,col in zip(axes,continous_features):\n",
        "  sns.kdeplot(df[col], ax=ax, fill=True)\n",
        "  ax.set_title(col)\n",
        "  ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4T92nB7Tnvy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **GRE & TOEFL**: Both are near-normal with peaks around ~315 (GRE) and ~107 (TOEFL), showing most candidates are strong scorers.\n",
        "    \n",
        "*   **CGPA**: Bell-shaped distribution centered near 8.5â€“9, with few at the lower end â†’ indicates competitive academic consistency.\n",
        "    \n",
        "*   **Chance of Admit**: Slight right skew, peaking near 0.7â€“0.8 â†’ majority of applicants cluster in medium-to-high admit probabilities."
      ],
      "metadata": {
        "id": "5u7s_6h2gi7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = ['University Rating', 'SOP', 'LOR ', 'Research']"
      ],
      "metadata": {
        "id": "ErflTqgNRqb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in numerical_features:\n",
        "  print(df[i].value_counts())"
      ],
      "metadata": {
        "id": "22nrrN85dkom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,axes = plt.subplots(2,len(numerical_features)//2,figsize=(14,6))\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax,col in zip(axes,numerical_features):\n",
        "  sns.countplot(x=col,data=df,ax=ax)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p3qcO12SdcSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **University Rating**: Majority applicants are from mid-tier universities (Rating 2â€“4), with Rating 3 most common (162).\n",
        "    \n",
        "*   **SOP Strength**: Distribution leans towards stronger SOPs (3.0â€“4.5), very few weak SOPs (â‰¤1.5).\n",
        "    \n",
        "*   **LOR Strength**: Similar to SOP, clustered around 3.0â€“4.0; weak LORs (â‰¤2) are rare.\n",
        "    \n",
        "*   **Research**: 56% of applicants (280) have research experience, 44% (220) do not â€” showing a balanced but slightly research-heavy dataset."
      ],
      "metadata": {
        "id": "gU-HyGIMgy92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,4))\n",
        "sns.scatterplot(x='GRE Score',y='Chance of Admit',data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LMPHsEVig1qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Strong **positive linear relationship** between GRE Score and Chance of Admit â€” higher GRE consistently aligns with higher admission probability.\n",
        "    \n",
        "*   Spread is tighter at the top (GRE â‰¥ 325 mostly admit chance â‰¥ 0.8), while at lower GRE (â‰¤ 305) admit chances vary widely â†’ GRE is influential but not the sole determinant."
      ],
      "metadata": {
        "id": "6ofjqgE0hBuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,4))\n",
        "sns.scatterplot(x='CGPA',y='Chance of Admit',data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DSSohhP8ogiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Very strong positive linear trend**: Higher CGPA almost directly translates into higher admit chances.\n",
        "    \n",
        "*   Students with **CGPA â‰¥ 9.0** generally have admission chances above 0.8, while those below 8.0 face wider uncertainty (0.4â€“0.7 range)."
      ],
      "metadata": {
        "id": "oz72mO07hM5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,4))\n",
        "sns.scatterplot(x='GRE Score',y='TOEFL Score',data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fhKxNRmqot8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Clear **positive correlation**: students with higher GRE scores also tend to have higher TOEFL scores.\n",
        "    \n",
        "*   Some spread exists in the mid-range (GRE 305â€“315) where TOEFL scores vary between 95â€“115, but overall the relationship is quite linear."
      ],
      "metadata": {
        "id": "NqH7xmFRhW_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "sns.kdeplot(df,x=\"Chance of Admit\",hue=\"University Rating\",fill=True,common_norm = False,palette='crest')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DonTlMFBpK7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Clear upward shift**: Higher-rated universities are associated with higher admit probabilities.\n",
        "    \n",
        "*   Distribution centers:\n",
        "    \n",
        "    *   Rating 1 peaks around ~0.55,\n",
        "        \n",
        "    *   Rating 3 around ~0.70,\n",
        "        \n",
        "    *   Rating 5 sharply concentrated near ~0.9.\n",
        "        \n",
        "*   Overlap exists between adjacent ratings, but the trend is **monotonic upward**."
      ],
      "metadata": {
        "id": "fAH_loUfhhcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "sns.kdeplot(df,x=\"Chance of Admit\",hue=\"Research\",fill=True,common_norm = False,palette='crest')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OQWUPkoMqJpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Applicants **with research experience (1)** show a distribution centered higher (~ 0.85) compared to those **without research (0)** (~0.75).\n",
        "    \n",
        "*   The curve for research students is narrower and shifted right, indicating consistently better admit chances.\n",
        "    \n",
        "*   Non-research profiles still get admits, but with lower and more spread-out probabilities."
      ],
      "metadata": {
        "id": "8YeTQr90hvRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "\n",
        "sns.kdeplot(df,x=\"Chance of Admit\",hue=\"SOP\",fill=True,common_norm = False,palette='Paired')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q1DzjzKruk2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Clear upward shift**: Higher SOP scores align with higher admit probabilities.\n",
        "    \n",
        "*   SOP = 1â€“2 peaks around 0.5â€“0.6, while SOP â‰¥ 4 shifts sharply to 0.8â€“0.9+.\n",
        "    \n",
        "*   Distributions overlap, but the progression is monotonic â€” stronger SOP consistently improves chances."
      ],
      "metadata": {
        "id": "4l-aMQzkiGIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "PlfaWR1fvy8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={\"LOR \":\"LOR\"},inplace=True)"
      ],
      "metadata": {
        "id": "X00ydW0FwDRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "\n",
        "sns.kdeplot(df,x=\"Chance of Admit\",hue=\"LOR\",fill=True,common_norm = False,palette='Paired')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AIno5l3DvqMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Positive trend**: Higher LOR ratings shift the admit probability curve to the right.\n",
        "    \n",
        "*   Weak LORs (â‰¤2.0) mostly peak around 0.5â€“0.6, while strong LORs (â‰¥4.0) concentrate in the 0.8â€“0.9+ range.\n",
        "    \n",
        "*   Some overlap exists, but overall higher LOR strength is strongly associated with higher admit chances."
      ],
      "metadata": {
        "id": "OTElKOgEiWXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr = df.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", linewidths=0.5,cmap='crest')\n",
        "plt.title(\"Correlation Matrix Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nyuL89JUowoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Strongest predictors of Chance of Admit**: CGPA (0.88), GRE (0.81), and TOEFL (0.79). These are the **primary academic drivers** of admission chances.\n",
        "    \n",
        "*   **Moderate impact variables**: University Rating (0.69), SOP (0.68), LOR (0.65) â†’ they supplement academics by improving overall profile strength.\n",
        "    \n",
        "*   **Research**: Positively correlated (0.55), showing value-add but less dominant than scores or GPA.\n",
        "    \n",
        "*   **High inter-correlation** among GRE, TOEFL, and CGPA (â‰¥0.8) â†’ raises potential **multicollinearity risk**, requiring VIF check before regression."
      ],
      "metadata": {
        "id": "sgYv_fbniowm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since GRE, TOEFL and CGPA are highly correalted we can add them and make one feature\n",
        "df['Total Score'] = (df['GRE Score']*10/340) + (df['TOEFL Score']*10/120) + df['CGPA']\n",
        "df.drop(['GRE Score', 'TOEFL Score', 'CGPA'], axis=1, inplace=True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3mXyj3cvo7YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **New academic composite created**: Total Score combines GRE, TOEFL, and CGPA into one holistic metric on a ~20â€“30 scale.\n",
        "    \n",
        "*   **Remaining features**: University Rating, SOP, LOR, and Research act as qualitative differentiators, with Chance of Admit as target.\n",
        "    \n",
        "*   âœ… Dataset is now balanced: **1 composite academic feature + 4 qualitative features â†’ target**."
      ],
      "metadata": {
        "id": "KpPB5ol2jKnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Chance of Admit', axis=1)\n",
        "y = df['Chance of Admit']\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "60u5ST4wWCBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "13DwU4G9WOFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "k9yz9rECWSol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "G56AoSLDWX69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "eqAJa5GWWcOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "-24GqSkkWhw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train"
      ],
      "metadata": {
        "id": "DAC2q5QZaQ9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_columns = X.columns\n",
        "# X_train_columns"
      ],
      "metadata": {
        "id": "kJGpvNyAcYFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.DataFrame(X_train, columns=X_train_columns)\n",
        "X_test = pd.DataFrame(X_test, columns=X_train_columns)\n",
        "X_train.head()"
      ],
      "metadata": {
        "id": "9GL9uG-_aYab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head()"
      ],
      "metadata": {
        "id": "O_cfHbxscS_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.describe()"
      ],
      "metadata": {
        "id": "5csyUKOwg7qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "hZyQkiOazgkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "0I71tEk5zxZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Coefficients: {lr_model.coef_}\")\n",
        "print(f\"Intercept: {lr_model.intercept_}\")"
      ],
      "metadata": {
        "id": "KSgkoYUjz0Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Total Score dominates**: With the highest coefficient (0.103), academic strength is the **single biggest driver** of admission chances.\n",
        "    \n",
        "*   **Qualitative lifts**: LOR (0.019) and Research (0.013) add meaningful boosts, highlighting the importance of profile quality beyond scores.\n",
        "    \n",
        "*   **Moderate role**: SOP (0.003) and University Rating (0.003) have smaller but still positive effects.\n",
        "    \n",
        "*   **Overall**: Admissions depend primarily on strong academics, but **supporting factors help differentiate applicants in the competitive middle band**."
      ],
      "metadata": {
        "id": "sRVrCPOUjh7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = lr_model.predict(X_train)\n",
        "y_test_pred  = lr_model.predict(X_test)"
      ],
      "metadata": {
        "id": "GGYXD-GLz4Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train, p = X_train.shape\n",
        "n_test = X_test.shape[0]"
      ],
      "metadata": {
        "id": "T9VLpqjh52vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "LaKnYGnb6Pl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_tr = mean_squared_error(y_train, y_train_pred)\n",
        "rmse_tr = np.sqrt(mse_tr)\n",
        "r2_tr = r2_score(y_train, y_train_pred)\n",
        "adj_r2_tr = 1 - (1 - r2_tr) * (n_train - 1) / (n_train - p - 1)\n",
        "\n",
        "print(\"Training Set\")\n",
        "print(f\"  RMSE    : {rmse_tr:.3f}\")\n",
        "print(f\"  R^2     : {r2_tr:.3f}\")\n",
        "print(f\"  Adj R^2 : {adj_r2_tr:.3f}\")"
      ],
      "metadata": {
        "id": "odvpSAHe6Ati"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_te = mean_squared_error(y_test, y_test_pred)\n",
        "rmse_te = np.sqrt(mse_te)\n",
        "r2_te = r2_score(y_test, y_test_pred)\n",
        "adj_r2_te = 1 - (1 - r2_te) * (n_test - 1) / (n_test - p - 1)\n",
        "\n",
        "print(\"\\nTest Set\")\n",
        "print(f\"  RMSE    : {rmse_te:.3f}\")\n",
        "print(f\"  R^2     : {r2_te:.3f}\")\n",
        "print(f\"  Adj R^2 : {adj_r2_te:.3f}\")"
      ],
      "metadata": {
        "id": "KkXHF_Ey64AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Training vs Test**: Very close scores (Train RÂ² = 0.81, Test RÂ² = 0.80) â†’ model is **stable and not overfitting**.\n",
        "    \n",
        "*   **Error levels**: RMSE ~0.06 on both sets â†’ on average, predictions deviate by just 6 percentage points in admit probability, which is **quite accurate** for real-world use.\n",
        "    \n",
        "*   **Adjusted RÂ² (~0.79â€“0.81)**: Confirms that predictors collectively explain ~80% of the variance in admit chances."
      ],
      "metadata": {
        "id": "LTMUsC-fjv3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "# Actual vs Predicted\n",
        "sns.scatterplot(x=y_test, y=y_test_pred, color=\"blue\")\n",
        "sns.regplot(x=y_test, y=y_test_pred, scatter=False, color=\"red\")\n",
        "plt.xlabel(\"Actual Chance of Admit\")\n",
        "plt.ylabel(\"Predicted Chance of Admit\")\n",
        "plt.title(\"Actual vs. Predicted (Linear Regression)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EKOSeY4e7FeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Points are closely aligned with the diagonal regression line â†’ shows the model is capturing the relationship well.\n",
        "    \n",
        "*   Only minor deviations exist, no major systematic bias.\n",
        "    \n",
        "*   âœ… Confirms **good predictive accuracy**."
      ],
      "metadata": {
        "id": "qp2Gr699kANF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "\n",
        "residuals = y_test - y_test_pred   # use predictions on test set\n",
        "sns.scatterplot(x=y_test, y=residuals, color=\"blue\")\n",
        "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Actual vs. Residuals (Test Set)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zLj1-ThuCDpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Residuals are scattered randomly around zero without a clear pattern â†’ satisfies **linearity assumption**.\n",
        "    \n",
        "*   Spread is fairly constant across the range of actual values â†’ indicates **no serious heteroscedasticity**.\n",
        "    \n",
        "*   âœ… Confirms residuals are centered near zero and model assumptions largely hold."
      ],
      "metadata": {
        "id": "OP9XqwxHkIFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get coefficients\n",
        "coefficients = lr_model.coef_\n",
        "features = X_train.columns  # feature names from your dataset\n",
        "\n",
        "# Put into DataFrame for easy plotting\n",
        "coef_df = pd.DataFrame({\n",
        "    \"Feature\": features,\n",
        "    \"Coefficient\": coefficients\n",
        "}).sort_values(by=\"Coefficient\", ascending=False)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.bar(coef_df[\"Feature\"], coef_df[\"Coefficient\"], color=\"steelblue\")\n",
        "plt.title(\"Model Coefficients\")\n",
        "plt.ylabel(\"Weights\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f-uCDxAgSrD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Total Score** is by far the strongest driver, confirming that overall academic strength dominates admit decisions.\n",
        "    \n",
        "*   **LOR** and **Research** have meaningful positive influence, showing that strong recommendations and research exposure significantly improve chances.\n",
        "    \n",
        "*   **SOP** and **University Rating** contribute positively but comparatively less, acting more as supporting enhancers."
      ],
      "metadata": {
        "id": "whibILGpkYS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "iy9QpcweToWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_sm = sm.add_constant(X_train)\n",
        "X_test_sm = sm.add_constant(X_test)\n",
        "\n",
        "ols_model = sm.OLS(np.array(y_train), X_train_sm).fit()\n",
        "print(ols_model.summary())"
      ],
      "metadata": {
        "id": "qom1O2FRUTnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Model explains ~81% of admit chance variance (RÂ² = 0.81) â†’ strong fit.\n",
        "    \n",
        "*   **Total Score** is the dominant driver; **LOR** and **Research** add significant positive impact.\n",
        "    \n",
        "*   **SOP** and **Univ Rating** are statistically weak in this setup, likely overshadowed by academics.\n",
        "    \n",
        "*   Residual checks show no major issues â†’ model is robust and reliable."
      ],
      "metadata": {
        "id": "x98uMP-lkoYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_sm_new = X_train_sm.drop(['SOP'], axis=1)\n",
        "ols_model_new = sm.OLS(np.array(y_train), X_train_sm_new).fit()\n",
        "print(ols_model_new.summary())"
      ],
      "metadata": {
        "id": "83Ky8D34UXKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model fit is strong (RÂ² = 0.81).\n",
        "\n",
        "Total Score dominates; LOR and Research add significant lifts.\n",
        "\n",
        "University Rating is not statistically significant.\n",
        "\n",
        "SOP was dropped this time due to low impact in earlier run, simplifying the model without hurting performance."
      ],
      "metadata": {
        "id": "j3Gpw9GklMB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_sm_new = X_train_sm.drop(['University Rating'], axis=1)\n",
        "ols_model_new = sm.OLS(np.array(y_train), X_train_sm_new).fit()\n",
        "print(ols_model_new.summary())"
      ],
      "metadata": {
        "id": "nI4vG2ijXInF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Model fit strong (RÂ² = 0.81).\n",
        "    \n",
        "*   **Total Score** dominates, with **LOR** and **Research** significant boosters.\n",
        "    \n",
        "*   **SOP remains statistically weak** (p = 0.42).\n",
        "    \n",
        "*   **University Rating was dropped** this time, simplifying the model without loss of accuracy."
      ],
      "metadata": {
        "id": "VI3NZum7lchj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ],
      "metadata": {
        "id": "9P3r6M6tXX0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_vif(X):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Feature\"] = X.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "    return vif_data"
      ],
      "metadata": {
        "id": "PF50cIb6X-3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vif_scores = calculate_vif(X_train)\n",
        "print(vif_scores)"
      ],
      "metadata": {
        "id": "eGS3gUkgYAdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   All VIF values are **< 5**, so **no serious multicollinearity** concern.\n",
        "    \n",
        "*   Total Score (2.86) and SOP (2.76) are the highest but still within safe limits.\n",
        "    \n",
        "*   âœ… Model predictors are independent enough for reliable OLS estimation."
      ],
      "metadata": {
        "id": "zX6h3fgvl_Vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = y_test - y_test_pred\n",
        "\n",
        "sns.set_theme(style='whitegrid')\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "plt.scatter(y_test_pred, residuals, alpha=0.8, color='blue', edgecolor='k', s=50)\n",
        "\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "\n",
        "plt.title('Residuals vs. Predicted Values', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Predicted Values', fontsize=14)\n",
        "plt.ylabel('Residuals', fontsize=14)\n",
        "\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ps7NjPL8YE0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Residuals are randomly scattered around zero â†’ **linearity assumption holds**.\n",
        "    \n",
        "*   Spread is fairly uniform across predicted values â†’ no clear signs of **heteroscedasticity**.\n",
        "    \n",
        "*   âœ… Confirms that the model errors behave randomly, supporting reliability of regression results."
      ],
      "metadata": {
        "id": "xQUK0k9HmKNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "sns.set_theme(style='dark')\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Histogram of Residuals\n",
        "sns.histplot(residuals, bins=30, kde=True, color='blue', ax=axs[0])\n",
        "axs[0].set_title('Histogram of Residuals', fontsize=16)\n",
        "axs[0].set_xlabel('Residuals', fontsize=14)\n",
        "axs[0].set_ylabel('Frequency', fontsize=14)\n",
        "axs[0].grid(False)\n",
        "\n",
        "# Q-Q Plot\n",
        "stats.probplot(residuals, dist=\"norm\", plot=axs[1])\n",
        "axs[1].get_lines()[1].set_color('orange')\n",
        "axs[1].get_lines()[0].set_markerfacecolor('red')\n",
        "axs[1].set_title('Q-Q Plot of Residuals', fontsize=16)\n",
        "axs[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0XoUj5qBYhLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Histogram**: Residuals are roughly bell-shaped and centered near zero, though with slight skew.\n",
        "    \n",
        "*   **Q-Q Plot**: Points mostly follow the diagonal line â†’ residuals are approximately normal, with mild deviations at the tails.\n",
        "    \n",
        "*   âœ… Assumption of normality is reasonably satisfied for regression."
      ],
      "metadata": {
        "id": "N3P4MkH-mUza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shapiro_stat, shapiro_p_value = stats.shapiro(residuals)\n",
        "print(f'Shapiro-Wilk Test Statistic: {shapiro_stat}, p-value: {shapiro_p_value}')\n",
        "\n",
        "if shapiro_p_value > 0.05:\n",
        "    print(\"Fail to reject the null hypothesis: Residuals are normally distributed.\")\n",
        "else:\n",
        "    print(\"Reject the null hypothesis: Residuals are not normally distributed.\")"
      ],
      "metadata": {
        "id": "pwvTx2YDZRCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Test result**: p-value â‰ˆ 2.5e-05 < 0.05 â†’ reject null; residuals are **not perfectly normal**.\n",
        "    \n",
        "*   **But**: With 400 observations, even small deviations trigger significance. Plots (histogram, Q-Q) already showed residuals are _approximately_ normal.\n",
        "    \n",
        "*   âœ… Conclusion: Slight non-normality exists, but itâ€™s not severe enough to invalidate regression results."
      ],
      "metadata": {
        "id": "FaooeUO3mfe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = ols_model.predict(X_test_sm)\n",
        "\n",
        "y_test = y_test.reset_index(drop=True)\n",
        "y_test_pred = y_test_pred.reset_index(drop=True)\n",
        "\n",
        "residuals = y_test - y_test_pred\n",
        "residuals.shape"
      ],
      "metadata": {
        "id": "A5YFv6OeankB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "\n",
        "bp_test = het_breuschpagan(residuals, X_test_sm)\n",
        "\n",
        "bp_labels = ['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value']\n",
        "bp_results = dict(zip(bp_labels, bp_test))\n",
        "\n",
        "print(bp_results)"
      ],
      "metadata": {
        "id": "yCQ9RamxavOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if bp_results['p-value'] > 0.05:\n",
        "    print(\"Fail to reject the null hypothesis: No evidence of heteroscedasticity.\")\n",
        "else:\n",
        "    print(\"Reject the null hypothesis: Heteroscedasticity may be present.\")"
      ],
      "metadata": {
        "id": "X25IVuvGay9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Test result: p-value â‰ˆ 0.16 > 0.05 â†’ fail to reject null.\n",
        "\n",
        "* âœ… Residual variance is constant â†’ no heteroscedasticity detected."
      ],
      "metadata": {
        "id": "RYaQpJHimtsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.diagnostic import het_goldfeldquandt\n",
        "\n",
        "gq_test = het_goldfeldquandt(ols_model.resid, ols_model.model.exog)\n",
        "gq_test_statistic = gq_test[0]\n",
        "gq_p_value = gq_test[1]\n",
        "\n",
        "print(\"Goldfeld-Quandt Test Statistic:\", gq_test_statistic)\n",
        "print(\"p-value:\", gq_p_value)"
      ],
      "metadata": {
        "id": "SCOvfP0Ua3HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if gq_p_value > 0.05:\n",
        "    print(\"Fail to reject the null hypothesis: No evidence of heteroscedasticity.\")\n",
        "else:\n",
        "    print(\"Reject the null hypothesis: Heteroscedasticity may be present.\")"
      ],
      "metadata": {
        "id": "_IGa0HpAbNZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Goldfeld-Quandt result**: Test statistic â‰ˆ 1.01, p-value â‰ˆ 0.48 (> 0.05) â†’ fail to reject null.\n",
        "    \n",
        "*   âœ… Confirms **no heteroscedasticity** in residuals."
      ],
      "metadata": {
        "id": "BuOYkWEom_VN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso_model = Lasso(alpha=0.1)\n",
        "lasso_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "RjDMBRHTbRHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_train_pred = lasso_model.predict(X_train)\n",
        "y_test_pred  = lasso_model.predict(X_test)\n",
        "\n",
        "# ----- Training set -----\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "rmse_train = np.sqrt(mse_train)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "adj_r2_train = 1 - (1 - r2_train) * (len(y_train) - 1) / (len(y_train) - X_train.shape[1] - 1)\n",
        "\n",
        "print(\"Training Set Evaluation:\")\n",
        "print(f\"  RMSE    : {rmse_train:.2f}\")\n",
        "print(f\"  R^2     : {r2_train:.2f}\")\n",
        "print(f\"  Adj R^2 : {adj_r2_train:.2f}\")\n",
        "\n",
        "# ----- Test set -----\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "adj_r2_test = 1 - (1 - r2_test) * (len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1)\n",
        "\n",
        "print(\"\\nTest Set Evaluation:\")\n",
        "print(f\"  RMSE    : {rmse_test:.2f}\")\n",
        "print(f\"  R^2     : {r2_test:.2f}\")\n",
        "print(f\"  Adj R^2 : {adj_r2_test:.2f}\")"
      ],
      "metadata": {
        "id": "1ddUlfm2ydMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = lasso_model.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "# Scatterplot\n",
        "sns.scatterplot(x=y_test, y=y_test_pred, color=\"blue\", alpha=0.6)\n",
        "\n",
        "# Regression line\n",
        "sns.regplot(x=y_test, y=y_test_pred, scatter=False, color=\"red\")\n",
        "\n",
        "plt.xlabel(\"Actual Chance of Admit\")\n",
        "plt.ylabel(\"Predicted Chance of Admit\")\n",
        "plt.title(\"Actual vs Predicted (Lasso Regression)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Glmd--fKysBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = lasso_model.predict(X_test)\n",
        "\n",
        "# Residuals = Actual - Predicted\n",
        "residuals = y_test - y_test_pred\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.scatterplot(x=y_test, y=residuals, color=\"blue\", alpha=0.6)\n",
        "\n",
        "# Horizontal line at 0 (perfect predictions)\n",
        "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "plt.xlabel(\"Actual Chance of Admit\")\n",
        "plt.ylabel(\"Residuals (Actual - Predicted)\")\n",
        "plt.title(\"Actual vs Residuals (Lasso Regression)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UF9GGt6AzshG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge_model = Ridge(alpha=0.1)\n",
        "ridge_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "N9THw4uGz8Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_train_pred = ridge_model.predict(X_train)\n",
        "y_test_pred  = ridge_model.predict(X_test)\n",
        "\n",
        "# ----- Training set -----\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "rmse_train = np.sqrt(mse_train)\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "adj_r2_train = 1 - (1 - r2_train) * (len(y_train) - 1) / (len(y_train) - X_train.shape[1] - 1)\n",
        "\n",
        "print(\"Training Set Evaluation:\")\n",
        "print(f\"  RMSE    : {rmse_train:.2f}\")\n",
        "print(f\"  R^2     : {r2_train:.2f}\")\n",
        "print(f\"  Adj R^2 : {adj_r2_train:.2f}\")\n",
        "\n",
        "# ----- Test set -----\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "adj_r2_test = 1 - (1 - r2_test) * (len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1)\n",
        "\n",
        "print(\"\\nTest Set Evaluation:\")\n",
        "print(f\"  RMSE    : {rmse_test:.2f}\")\n",
        "print(f\"  R^2     : {r2_test:.2f}\")\n",
        "print(f\"  Adj R^2 : {adj_r2_test:.2f}\")"
      ],
      "metadata": {
        "id": "Z2-Z-7qOz_aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = ridge_model.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "# Scatterplot\n",
        "sns.scatterplot(x=y_test, y=y_test_pred, color=\"blue\", alpha=0.6)\n",
        "\n",
        "# Regression line\n",
        "sns.regplot(x=y_test, y=y_test_pred, scatter=False, color=\"red\")\n",
        "\n",
        "plt.xlabel(\"Actual Chance of Admit\")\n",
        "plt.ylabel(\"Predicted Chance of Admit\")\n",
        "plt.title(\"Actual vs Predicted (Lasso Regression)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gb_V6Ser0H3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = ridge_model.predict(X_test)\n",
        "\n",
        "# Residuals = Actual - Predicted\n",
        "residuals = y_test - y_test_pred\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.scatterplot(x=y_test, y=residuals, color=\"blue\", alpha=0.6)\n",
        "\n",
        "# Horizontal line at 0 (perfect predictions)\n",
        "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "plt.xlabel(\"Actual Chance of Admit\")\n",
        "plt.ylabel(\"Residuals (Actual - Predicted)\")\n",
        "plt.title(\"Actual vs Residuals (Lasso Regression)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ErQoUNVp0ZVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **OLS**: Performed strongly (RÂ² â‰ˆ 0.81, RMSE â‰ˆ 0.06) with interpretable coefficients; assumptions mostly satisfied.\n",
        "    \n",
        "*   **Ridge**: Similar predictive power, helps stabilise coefficients if correlated features exist; slight shrinkage but no major gains since multicollinearity was low (VIF < 5).\n",
        "    \n",
        "*   **Lasso**: Introduces feature selection by shrinking less important coefficients toward zero; confirmed SOP/Univ Rating had low impact.\n",
        "    \n",
        "*   **Conclusion**: OLS is interpretable and sufficient here, while Ridge/Lasso validate robustness and highlight variable importance."
      ],
      "metadata": {
        "id": "w-yU-UZ9xDuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”¹ Insights\n",
        "-----------\n",
        "\n",
        "*   **Model performance**: Both the base Linear Regression and Ridge Regression models performed strongly, explaining ~81% of the variance in admission chances (RÂ² â‰ˆ 0.81, RMSE â‰ˆ 0.06). The Lasso model, while useful for feature selection, did not improve predictive accuracy in this dataset.\n",
        "    \n",
        "*   **Feature importance**: The engineered Total Score (combined GRE, TOEFL, and CGPA) emerged as the most influential predictor of admit probability. Among qualitative variables, **Letter of Recommendation (LOR)** and **Research Experience** showed significant positive contributions, while **University Rating** and **SOP Strength** had limited standalone impact.\n",
        "    \n",
        "*   **Collinearity considerations**: The original exam-related features (GRE, TOEFL, CGPA) were highly correlated with each other. Consolidating them into a single Total Score feature improved interpretability and reduced multicollinearity without reducing model accuracy.\n",
        "    \n",
        "*   **Assumption validation**: All major assumptions of linear regression were satisfied â€” residuals showed linearity and homoscedasticity, and VIF values indicated no serious multicollinearity. Although the Shapiro-Wilk test flagged residuals as not perfectly normal, both histogram and Q-Q plots showed only minor deviations, acceptable for practical regression use.\n",
        "    \n",
        "\n",
        "ðŸ‘‰ **Business takeaway**: Admission outcomes are primarily determined by **academic strength**, with **research exposure and strong recommendations** acting as key differentiators. SOPs and University Rating play a marginal role in this dataset, but could matter in borderline or subjective cases.\n",
        "\n",
        "ðŸ”¹ Recommendations\n",
        "------------------\n",
        "\n",
        "*   **Improve dataset balance**: The target variable (Chance of Admit) is right-skewed, with most applicants having medium-to-high admit chances. Collecting more data on rejected candidates would provide better variance and improve prediction robustness.\n",
        "    \n",
        "*   **Enhance feature set**: To capture the holistic nature of graduate admissions, additional independent variables can be introduced, such as:\n",
        "    \n",
        "    *   **Work Experience** â€“ indicates practical skills and maturity.\n",
        "        \n",
        "    *   **Internships** â€“ reflect application of knowledge in real-world settings.\n",
        "        \n",
        "    *   **Extracurricular Activities** â€“ highlight leadership, teamwork, and diverse strengths.\n",
        "        \n",
        "    *   **Diversity Variables** â€“ capture socio-cultural diversity that institutions often value.\n",
        "        \n",
        "*   **Model choice**: For interpretability, OLS remains the preferred baseline, while Ridge can be deployed in production for coefficient stability if future features increase multicollinearity. Lasso is useful when feature selection is required on larger datasets.\n",
        "    \n",
        "*   **Business application**: The model can be integrated into Jamboreeâ€™s admission counselling platform as a **â€œChance of Admit Estimatorâ€**, guiding students on where to invest efforts (e.g., improve GRE/CGPA, pursue research, strengthen LORs). This not only supports students but also helps Jamboree **prioritise high-potential leads** and tailor services more effectively."
      ],
      "metadata": {
        "id": "7-UJ5VsjxfHg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8pDdehzixf0B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}